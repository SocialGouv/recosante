# Recosante

Recosante : Un service public num√©rique de recommandations d'actions pour r√©duire l'impact de l'environnement sur sa sant√©.

Accessible sur https://recosante.beta.gouv.fr/

Ce d√©p√¥t est un monorepo cr√©√© pour faciliter le d√©ploiement sur l'infrastructure de la [Fabrique num√©rique des minist√®res sociaux](https://fabrique.social.gouv.fr).

Les sous-dossiers ont √©t√© repris du travail effectu√© par l'√©quipe d√©di√©e de beta.gouv.fr, √† partir des d√©p√¥ts suivant :

- https://github.com/betagouv/recosante : frontend
- https://github.com/betagouv/recosante-api : data, envoi des emails
- https://github.com/betagouv/recosante-mail : templates email
- https://github.com/betagouv/indice_pollution : import des indices et utilisation via l‚ÄôAPI

## Br√®ve description

Recosant√© est compos√© de trois services :

- Une API d‚Äôexposition des indicateurs qui est dans ce d√©pot, techniquement il s‚Äôagit d‚Äôune API √©crite en python avec le framework Flask.
  Cette API sert aussi √† g√©rer les abonnements au service.

- Un service qui envoie les newsletters, techniquement c‚Äôest un worker celery qui est passe toutes les heures pour voir s‚Äôil doit envoyer des mails ou bien des notifications web.

- Un service qui sauvegarde les diff√©rents indices (indice ATMO, √©pisodes de pollution, Risque d'allergie li√© √† l'exposition aux pollens (RAEP), vigilance m√©t√©o, indice UV). Le code de ce service se trouve [ici](./libs/indice_pollution).

Les donn√©es sont stock√©es dans une base de donn√©es postgresql, dans le sch√©ma public pour les donn√©es d‚Äôabonnements, et dans le sch√©ma `indice_schema` pour les donn√©es de pr√©visions des diff√©rents indices renvoy√©s.

## Structure et projets

### indice_pollution

Ce projet utilise [`celery`](https://docs.celeryq.dev/en/stable/index.html) pour interroger diff√©rentes API (AirParif, indice ATMO r√©gionaux, ...) et alimenter sa propre base de donn√©es (shema `indice_schema`) toutes les heures.

Il s'exporte de plus comme une librairie utilisable par nimporte quel projet.

Plus d'information dans le [`README.md`](./libs/indice_pollution/README.md) du projet.

### api

Ce projet utilise √©galement [`celery`](https://docs.celeryq.dev/en/stable/index.html) pour g√©n√©rer des envois de mails aux utilisateurs ayant souscrit √† la newsletter via Brevo (ex sendInBlue). Il contient une API [`flask`](https://flask.palletsprojects.com/en/2.3.x/) qui sert la data n√©cessaire au site web. Il comporte un schema propre lui permettant de stocker les utilisateurs, newsletters et incriptions. Il utilise enfin la librarie `indice_pollution` pour interroger le schema `indice_schema`.

Plus d'information dans le [`README.md`](./api/README.md) du projet.

### frontend

Ce projet est le site recosant√©. Il utilise [Gatsby](https://www.gatsbyjs.com/).

Plus d'information dans le [`README.md`](./frontend/README.md) du projet.

### mail

Ce projet contient les templates mails utilis√©s par Brevo (ex sendInBlue).

Plus d'information dans le [`README.md`](./mail/README.md) du projet.

### Stack technique

Notre stack technique est principalement compos√©e de :

- front-end : React, Gatsby.
- back-end : Python, Flask, Celery / Redis, PostgreSQL.
- h√©bergement et autres services : Docker, Kubernetes, Brevo (ex Sendinblue).

### Sch√©ma simplifi√© d'architecture

```mermaid
flowchart TD
    subgraph Internet
        user[Utilisateur]
        brevo["Brevo (Ex SendInBlue)"]
        subgraph apis[APIs externes]
            atmo[API ATMO data par r√©gion]
            airparif[API AirParif]
            ftp[FTP clever cloud]
        end
    end

    subgraph Azure
        subgraph Kubernetes
            frontend[Service FrontEnd]
            flower["Service Flower (Celery UI)"]
            redis[Sevice Redis]
            subgraph serviceAPI[Service API]
                api[API]
                celeryAPI[Celery]
                indiceLib[Librairie Indice pollution]
            end

            subgraph serviceIndice[Service Indice pollution]
                indice[Indice pollution]
                celeryIndice[Celery]
            end
        end

        subgraph PostgreSQL
            apiSchema[API Schema]
            indiceSchema[Indice Schema]
        end
    end

    user-->|consulte|frontend
    user-->|no auth|api
    user-->|basic-auth|flower
    flower-->redis
    celeryAPI-->redis
    celeryIndice-->redis
    frontend<-->|data|serviceAPI
    serviceAPI<-->|data|apiSchema
    brevo<-->|sync + gestion mails|celeryAPI
    celeryIndice-->|synchro toutes les heures|indiceSchema
    apis-->|data|celeryIndice
    indiceSchema-->|requ√™tes|indiceLib
    indiceLib-->|requ√™tes|api
```

## R√©colte des donn√©es pour les indicateurs

### Baignades

1. [le frontend](frontend/src/hooks/useBaignades.js) utilise le code INSEE de la commune pour requ√™ter le backend
2. de ce code INSEE on requ√™te notre base de donn√©es (table indice_schema/commune) qui contient 35096 communes, afin de r√©cup√©rer le code du d√©partement (01, 02, 03...)
3. de ce code d√©partement on r√©cup√®re aussi un `idCarte` (`fra`, `reu`, `may`, `guy`, `mar`...)
4. on ex√©cute une requ√™te non authentifi√©e vers `https://baignades.sante.gouv.fr/baignades/siteList.do?idCarte={0}&insee_com={1}&code_dept={2}&f=json` avec les param√®tres r√©cup√©r√©s pr√©c√©demment afin de r√©cup√©rer la liste des sites de baignades concern√©s
5. on cr√©e un code d√©partement `dptddass` (le code d√©partement en 3 chiffres, pr√©c√©d√©s de 0 si n√©cessaire)
6. on extrait de la requ√™te effectu√©e en 4 un `isite` gr√¢ce auquel on compose un nouvel id de site `idSite` (`{dptddass}{isite}`)
7. on calcule l'ann√©e concern√©e, diff√©rente selon les h√©misph√®res
8. on ex√©cute une requ√™te non authentifi√©e vers `https://baignades.sante.gouv.fr/baignades/consultSite.do?dptddass={0}&site={1}&annee={2}` qui renvoie un html
9. on parse ce html afin de retrouver les informations que l'on souhaite: D√©but de la saison, Fin de la saison, Interdictions le cas √©ch√©ant, Observations, √âchantillons, Rang.
10. on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/baignades.py#L65) l'ensemble des informations disponibles

### Potentiel Radon

Le Potentiel Radon n'est pas une donn√©e dynamique

1. [le frontend](frontend/src/hooks/useBaignades.js) utilise le code INSEE de la commune pour requ√™ter le backend
2. de ce code INSEE on requ√™te notre base de donn√©es (table indice_schema/potentiel_radon) qui contient 35002 communes, afin de r√©cup√©rer le potentiel (entre 1 et 3)
3. on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/blueprint.py#L89)

### Indice UV

1. chaque matin √† 7h un fichier `YYYYMMDD.csv` contenant les indices UV de la journ√©e est d√©pos√© par une tierce partie sur un bucket Clever Cloud. Ce fichier est structur√© de cette mani√®re pour quelques 36608 communes: `Code insee`, `Commune`, `Date`, `UV_J0`, `UV_J1`, `UV_J2`, `UV_J3`.
2. un [cron job](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/__init__.py#148) est ex√©cut√© toute les heures pour se connecter via FTP au bucket et [r√©cup√©rer les indices UV](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/history/models/indice_uv.py#L30).
3. toutes les donn√©es sont enregistr√©es en base de donn√©es dans la table `indice_schema/indice_uv` (19 millions de lignes fin ao√ªt 2023)
4. ainsi pour chaque requ√™te du frontend, on requ√™te notre base de donn√©es et on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/blueprint.py#L130)

### RAEP (Risque d'allergie li√© √† l'exposition aux pollens)

1. un [cron job](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/__init__.py#143) est ex√©cut√© toute les heures pour [faire une requ√™te](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/history/models/raep.py#L81) non authentifi√©e vers `https://www.pollens.fr/docs/ecosante.csv` qui renvoie un csv avec toutes les donn√©es pour chaque d√©partement de France m√©tropolitaine
2. ces donn√©es sont valables pour une semaine, de mercredi √† mercredi.
3. on parse ce CSV et on alimente notre base de donn√©es dans la table `indice_schema/raep`
4. le frontend fait une requ√™te avec le code INSEE de la commune, et le backend trouve le code d√©partement associ√©
5. ainsi pour chaque requ√™te du frontend, on requ√™te notre base de donn√©es et on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/blueprint.py#L120)

### Vigilance m√©t√©o

2. un [cron job](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/__init__.py#145) est ex√©cut√© toute les heures pour [faire une requ√™te](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/history/models/vigilance_meteo.py#L77) authentifi√©e vers `https://public-api.meteofrance.fr/public/DPVigilance/v1/cartevigilance/encours` qui renvoie un JSON avec touts les donn√©es √† la date d'aujourd'hui et demain
3. ce json est pars√© et on alimente notre base de donn√©es dans la table `indice_schema/vigilance_meteo`, avec des donn√©es par d√©partement
4. le frontend fait une requ√™te avec le code INSEE de la commune, et le backend trouve le code d√©partement associ√©
5. ainsi pour chaque requ√™te du frontend, on requ√™te notre base de donn√©es et on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/blueprint.py#106)

### Indices ATMO

Cette partie est la plus d√©licate :) puisqu'elle n√©cessite de r√©cup√©rer des donn√©es de beaucoup de sources diff√©rentes, par r√©gion

1. Un [cron job](https://github.com/SocialGouv/recosante/blob/master/libs/indice_pollution/indice_pollution/__init__.py#138) est ex√©cut√© toute les heures pour [faire une requ√™te](https://github.com/SocialGouv/recosante/blob/b2c828cedb065b57c7d151377418b9dcf348edb0/libs/indice_pollution/indice_pollution/regions/__init__.py#L172) vers une API ou un site sur lequel on peut scrapper les donn√©es et les r√©cup√©rer en format JSON. Si les donn√©es sont r√©cup√©r√©es par une API alors les formats sont g√©n√©ralement identiques (format normalis√©) m√™me si les donn√©es peuvent √™tre r√©cup√©r√©es sur diff√©rents sites selon les r√©gions.
2. Pour chaque code insee(zone_id), on associe les donn√©es `no2`, `so2`, `o3`, `pm10`, `pm25`, `valeur`, `date_ech` (date de la journ√©e pr√©dite) et `date_diff`(date lorsque la pr√©diction a √©t√© effectu√©e) pour ensuite alimenter la base de donn√©es `indice_schema/IndiceATMO`, en mettant √† jour les donn√©es existantes s'il y en a.
3. Le frontend fait une requ√™te avec le code INSEE de la commune, et le backend trouve la zone associ√©e dans la base de donn√©es.
4. Ainsi pour chaque requ√™te du frontend, on requ√™te notre base de donn√©es et on [renvoie au frontend](https://github.com/SocialGouv/recosante/blob/master/api/ecosante/api/blueprint.py#85)

Pour chaque r√©gion, voici le d√©tail concernant la r√©cup√©ration des donn√©es avec l'API ou le scrapping :

#### Auvergne-Rh√¥ne-Alpes

Scrapping (mais en r√©alit√© simple requ√™te API) : Requ√™te authentifi√©e vers `https://api.atmo-aura.fr/api/v1/communes/{insee}/indices/atmo?api_token={api_key}&date_debut_echeance={date_}` qui renvoie un JSON avec toutes les donn√©es √† partir de la date du jour.

#### Bourgogne-Franche-Comt√© (ne fonctionne pas)

Requ√™te API non authentifi√©e vers `https://atmo-bfc.iad-informatique.com/geoserver/ows` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25) √† partir de la date du jour.

#### Bretagne  (ne fonctionne pas)

Requ√™te API non authentifi√©e vers `https://data.airbreizh.asso.fr/geoserver/ind_bretagne/ows` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25) √† partir de la date du jour.



#### Centre-Val de Loire
Dans le code il semble que ce soit : https://www.ligair.fr/ville/city?q=01400 (o√π le code postal est envoy√© en params via 'q'.
https://github.com/SocialGouv/recosante/blob/46e5d33a5475ff091eb286f6f86413e7a13e13e6/libs/indice_pollution/indice_pollution/regions/Centre-Val%20de%20Loire.py#L72
Mais je ne re√ßois que des tableaux vides ensuite.

Requ√™te API non authentifi√©e vers `https://geo.api.gouv.fr/communes/{insee}` pour r√©cup√©rer le code postal de la ville, puis requ√™te vers `http://www.ligair.fr/ville/city` pour r√©cup√©rer le nom de la ville dans le bon format pour ensuite scrapper `http://www.ligair.fr/commune/{ville_bon_format}` pour r√©cup√©rer les polluants responsables des d√©gradations de la qualit√© de l'air.

#### Corse

Requ√™te API non authentifi√©e vers `https://services9.arcgis.com/VQopoXNvUqHYZHjY/arcgis/rest/services/indice_atmo_communal_corse/FeatureServer/0/query?outFields=*&outSR=4326&f=json&orderByFields=date_ech DESC&where=date_ech >= CURRENT_DATE - INTERVAL '1' DAY` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25) √† partir de la date du jour.

#### Grand Est

Requ√™te API non authentifi√©e vers `https://opendata.arcgis.com/api/v3/datasets/b0d57e8f0d5e4cb786cb554eb15c3bcb_0/downloads/data?format=geojson&spatialRefId=4326` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### Guadeloupe

[√Ä PR√âCISER]
Requ√™te sur `https://services8.arcgis.com/7RrxpwWeFIQ8JGGp/arcgis/rest/services/ind_guadeloupe_1/FeatureServer/0/query`: il s'agit d'une page o√π il faudrait faire du scrapping - mais aucun signe de scrapping dans la codebase üßê.

#### Guyane

Requ√™te API non authentifi√©e vers `https://dservices8.arcgis.com/5JImMrIjAqUJnR3H/arcgis/services/ind_guyane_nouvel_indice/WFSServer?service=wfs&version=2.0.0&request=getfeature&typeName=ind_guyane_nouvel_indice:ind_guyane_agglo&outputFormat=GEOJSON` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### Hauts-de-France

Requ√™te sur `https://services8.arcgis.com/7RrxpwWeFIQ8JGGp/arcgis/rest/services/ind_guadeloupe_1/FeatureServer/0/query`: il s'agit d'une page o√π il faudrait faire du scrapping - mais aucun signe de scrapping dans la codebase üßê.

#### √éle-de-France

Requ√™te API authentifi√©e vers `https://api.airparif.asso.fr/indices/prevision/commune?insee={insee}` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### Martinique

Requ√™te API non authentifi√©e vers `https://services1.arcgis.com/y8pKCLYeLI1K2217/arcgis/rest/services/Indice_QA/FeatureServer/0/query?where=1=1&f=json&returnGeometry=False&orderByFields=ESRI_OID&outFields=*` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### Mayotte

Pas de donn√©es r√©cup√©r√©es.

#### Normandie

Requ√™te API non authentifi√©e vers `https://api.atmonormandie.fr/index.php/lizmap/service/?project=flux_indice_atmo_normandie&repository=dindice&OUTPUTFORMAT=GeoJSON&SERVICE=WFS&REQUEST=GetFeature&dl=1&TYPENAME=ind_normandie_3jours&VERSION=1.0.0` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### Nouvelle-Aquitaine

Requ√™te API non authentifi√©e vers `https://opendata.atmo-na.org/geoserver/alrt3j_nouvelle_aquitaine/wfs?service=wfs&request=getfeature&typeName=alrt3j_nouvelle_aquitaine:alrt3j_nouvelle_aquitaine&outputFormat=json&PropertyName=code_zone,lib_zone,date_ech,date_dif,code_pol,lib_pol,etat,couleur,com_court,com_long` qui renvoie un GeoJSON du type suivant, que l'on mappe ensuite avec notre sch√©ma de donn√©es:

```
{
    "type": "Feature",
    "id": "alrt3j_nouvelle_aquitaine.26",
    "geometry": null,
    "properties": {
        "code_zone": "17",
        "lib_zone": "CHARENTE-MARITIME",
        "date_ech": "2023-09-05T10:00:00Z",
        "date_dif": "2023-09-04T16:16:34.233Z",
        "code_pol": "1",
        "lib_pol": "Dioxyde de soufre",
        "etat": "PAS DE DEPASSEMENT",
        "couleur": "#19ff19",
        "com_court": null,
        "com_long": null
    }
}
```

#### Occitanie

Requ√™te API non authentifi√©e vers `https://geo.api.gouv.fr/communes/{insee}` pour r√©cup√©rer le nom de la ville dans son bon format pour ensuite scrapper `https://www.atmo-occitanie.org/{ville_bon_format}`.

#### Pays de la Loire

Requ√™te API non authentifi√©e vers `https://data.airpl.org/geoserver/ind_pays_de_la_loire/wfs?version=2.0.0&typeName=ind_pays_de_la_loire:ind_pays_de_la_loire&service=WFS&outputFormat=application/json&request=GetFeature&CQL_FILTER=date_ech >= '2023-09-04T00:00:00Z'` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

#### R√©union

Pas de donn√©es r√©cup√©r√©es.

#### Sud

Requ√™te API non authentifi√©e vers `https://geoservices.atmosud.org/geoserver/ind_sudpaca/ows?service=WFS&version=1.1.0&request=GetFeature&typeName=ind_sudpaca:ind_sudpaca&CQL_FILTER=date_ech >= '2023-09-04T00:00:00Z'&outputFormat=json` qui renvoie un JSON avec toutes les donn√©es (chaque code insee avec son code no2, so2, o3, pm10, pm25).

## D√©veloppement

### Requirements

Le projet est bas√© sur les outils suivant

```
# Environnements conteneuris√©s
docker
docker-compose

# Projets python
python
pip
poetry

# Projets JavaScript
node
npm
yarn
```

Si vous souhaitez lancer le projet en local, nous vous invitons √† installer tous ces binaires et √† les avoir diponibles dans le `PATH` de votre terminal.

### Lancer tous les services

Tous les services peuvent √™tre lanc√©s via la commande

```bash
yarn start
```

ou

```bash
docker-compose up
```

### Lancer les services en local

Merci de vous r√©f√©rer au `README.md` de chaque projet que vous souhaitez lancer en local. Gardez en m√©moire que ces projets ont besoin d'autres services pour fonctionner (base de donn√©es, redis...). Afin de lancer en local le minimum n√©cessaire √† l'ex√©cution de chaque projet, vous pouvez utiliser la commande

```bash
yarn up
```

### Stopper les conteneurs

A tout moment, vous pouvez stopper les conteneurs docker via les commandes

```bash
yarn stop
```

ou

```bash
docker-compose stop
```

Stoppera les conteneurs

```bash
yarn down
```

ou

```bash
docker-compose down
```

Stoppera et supprimera les conteneurs

Les volumes bases de donn√©es seront conserv√©s. Si vous souhaitez les supprimer, veuillez le faire manuellement avec `docker volume`.

### Tester

Afin d'ex√©cuter les tests unitaires, merci de vous r√©f√©rer au `README.md` de chaque projet afin de pr√©parer les variables d'environnement n√©cessaires. Une fois les instructions compl√©t√©es, vous pouvez utiliser la commande

```bash
yarn test
```

√† la racine du projet.

### Linter

Afin d'ex√©cuter le lint, merci de vous r√©f√©rer au `README.md` de chaque projet afin de pr√©parer les d√©pendances n√©cessaires. Une fois les instructions compl√©t√©es, vous pouvez utiliser la commande

```bash
yarn lint
```

Le projet utilise [pylint](https://github.com/pylint-dev/pylint). Pour autoformatter votre code avec `vsCode`, nous vous conseillons les extensions suivantes

- [Pylint](https://github.com/microsoft/vscode-pylint)
- [Pylance](https://github.com/microsoft/pylance-release)
- [isort](https://github.com/microsoft/vscode-isort)
- [autopep8](https://github.com/microsoft/vscode-autopep8)

`Nota Bene`

Lorsque vous d√©veloppez sur la librairie `indice_pollution` ou sur l'`api`, vous devez utiliser leur virtual environnement respectifs. Cela peut √™tre fait sous vscode en utilisant la commande `command + shift + p`, puis `Python: Select Interpreter` et choisir celui que vous souhaitez dans la liste afin que les d√©pendances soient r√©solues correctement.

Il faut que les `.venv` des projets soient install√©s avec `poetry` pour que `vsCode` les d√©tecte. Merci de vous r√©f√©rer aux `README.md` de chaque projet.

`pylint` va v√©rifier l'ordre des imports. Pour les formatter automatiquement, nous vous conseillons d'utiliser `isort`. Cependant, il y a une limitation d'`isort` consid√©rant les r√©pertoires locaux comme des libraries. Vous pouvez lui sp√©cifier de la configuration via vos settings `vsCode` (`settings.json` racine ou workspace).

```json
{
  "isort.args": ["--known-local-folder", "ecosante", "--known-local-folder", "tests"]
}
```

Pour l'`api`

```json
{
  "isort.args": ["--known-local-folder", "indice_pollution"]
}
```

Pour la librairie `indice_pollution`

## Contribution et deploiement continu

Chaque contribution fonctionnelle se fait sous la forme de pull-requests.

A chaque cr√©ation et mise √† jour de pull-request, une nouvelle version de l‚Äôapplication est d√©ploy√©e sur le cluster kubernetes de la fabrique dans un environnement de d√©mo (preview) qui lui est propre.

Une fois la pull-request valid√©e, le merge dans la branche master va d√©clencher le d√©ploiement dans l'environnement de pr√©-production sans interruption de service.

Pour d√©ployer en production, une task github est disponible.

## Licence

Apache 2.0 - Direction du num√©rique des minist√®re sociaux.

Voir [LICENSE](./LICENSE)
